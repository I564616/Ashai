INSERT_UPDATE ScriptingJob	;code[unique=true]		;scriptURI
							;asahiSAMAccessExportScriptJob	;model://asahiSAMAccessExportScript
							
INSERT_UPDATE CronJob	;code[unique=true]			;job(code)				;sessionLanguage(isocode)	;sessionUser(uid)
						;asahiSAMAccessExportScriptCronJob	;asahiSAMAccessExportScriptJob	;en		;admin

INSERT_UPDATE Script; code[unique=true];content;active[default=true, unique=true]
;asahiSAMAccessExportScript;"import java.io.File;
import java.lang.Exception;
import java.io.InputStream;
import de.hybris.platform.util.CSVConstants;
import java.io.IOException;

import java.util.Date;
import java.text.SimpleDateFormat;
import java.sql.Timestamp;
import org.apache.log4j.Logger;
import org.apache.commons.io.IOUtils;
import com.google.common.base.Stopwatch;

import de.hybris.platform.servicelayer.impex.ExportConfig;
import de.hybris.platform.servicelayer.impex.ExportConfig.ValidationMode;
import de.hybris.platform.servicelayer.impex.ExportResult;
import de.hybris.platform.servicelayer.impex.ExportService;
import de.hybris.platform.servicelayer.impex.ImpExResource;
import de.hybris.platform.impex.model.ImpExMediaModel;
import de.hybris.platform.impex.jalo.exp.ImpExExportMedia;
import de.hybris.platform.servicelayer.impex.impl.StreamBasedImpExResource;
import de.hybris.platform.impex.model.exp.ImpExExportMediaModel;
import com.apb.core.model.AsahiSAMAccessModel;
import de.hybris.platform.servicelayer.search.FlexibleSearchQuery;
import de.hybris.platform.servicelayer.search.SearchResult;
import de.hybris.platform.impex.model.cronjob.ImpExExportCronJobModel;

final Logger LOG = Logger.getLogger(""asahi"");

flexibleSearchService = spring.getBean(""flexibleSearchService"");

def exportService = spring.getBean(""exportService"");

final FlexibleSearchQuery query = new FlexibleSearchQuery(""select {pk} from {AsahiSAMAccess}"");

final SearchResult<AsahiSAMAccessModel> result1 = flexibleSearchService
		.search(query);
int count = result1.getCount();
int batch = result1.getCount() > 25000 ? 25000 : result1.getCount();

LOG.info(""Total record count ######"" +count);
	
int i=0;
if (count > 0) {

while (i < count ){

	final Stopwatch stopwatch = Stopwatch.createUnstarted();
	stopwatch.start();
	
	header = ""insert AsahiSAMAccess;approvalDenied[allownull=true];b2bCustomer(uid);orderAccess[allownull=true];payAccess[allownull=true];payer(uid);pendingApproval[allownull=true];requestDate[dateformat=yyyy-MM-dd HH:mm:ss.SSS ZZZZ];creationtime[forceWrite=true,dateformat=yyyy-MM-dd HH:mm:ss.SSS ZZZZ];modifiedtime[forceWrite=true,dateformat=yyyy-MM-dd HH:mm:ss.SSS ZZZZ];\n""+
	""\""#% impex.exportItemsFlexibleSearch(\""\""SELECT {pk} FROM {AsahiSAMAccess}\""\"", Collections.EMPTY_MAP, Collections.singletonList( Item.class ), false, true, ${i}, ${batch} );\""\n"";                                                   

	InputStream resourceAsStream  = null;
	try {
		resourceAsStream = new ByteArrayInputStream(header.getBytes());
		final ImpExResource resource = new StreamBasedImpExResource(resourceAsStream, CSVConstants.DEFAULT_ENCODING);
		final ExportConfig config = new ExportConfig();
		config.setScript(resource);
		config.setValidationMode(ValidationMode.WITHOUT);
		config.setSingleFile(true);
		char c=',';
		config.setFieldSeparator(c);
		config.setExportedDataCode(""23-asahiSAMAccess-""+new SimpleDateFormat(""yyyyMMddHHmmssSSS"").format(new Date()));
		final ExportResult result = exportService.exportData(config);
		stopwatch.stop();
		if (result.isError()){
			LOG.error(""Exception occurred during export"");
		} else {
			LOG.info(""Time taken to export AsahiSAMAccess for batch size : ""  + batch +""......"" + stopwatch.toString());
		}
		resourceAsStream.close();
	}
	catch (final Exception exception) {
			LOG.log(Level.ERROR, exception.getMessage());	
			
		}
	finally
		{
			resourceAsStream.close();
		}
	
	i=i+batch;
} 
	
}";;
